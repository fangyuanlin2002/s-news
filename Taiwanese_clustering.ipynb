{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manage data\n",
    "import pandas as pd\n",
    "from urllib.parse import quote_plus\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm.auto import tqdm  # Updated import\n",
    "\n",
    "# embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# translation\n",
    "from transformers import pipeline\n",
    "\n",
    "# dimensionality reduction\n",
    "import umap\n",
    "\n",
    "# clustering\n",
    "import hdbscan\n",
    "\n",
    "# extract keywords from texts\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# visualization\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# —— CONFIG —— \n",
    "SAMPLE_SIZE = 200\n",
    "BATCH_SIZE = 32\n",
    "EMBED_MODEL = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "TRANSLATE_MODEL = \"Helsinki-NLP/opus-mt-zh-en\"\n",
    "UMAP_KWARGS = dict(n_components=10, n_neighbors=15, min_dist=0.01)\n",
    "HDBSCAN_KWARGS = dict(\n",
    "    min_cluster_size=3,    # Small cluster sizes allowed\n",
    "    min_samples=1,         # Higher sensitivity for density\n",
    "    cluster_selection_epsilon=0.05 # Explicitly control distance for merging clusters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 articles\n",
      "   id                                title  \\\n",
      "0   1       \\n  谷歌在美砸250億美元 建資料中心和AI基礎設施\\n   \n",
      "1   2                  \\n  川普再度施壓Fed調降利率\\n   \n",
      "2   3            \\n  台電員工遭高壓線路電擊　卓榮泰關注不捨\\n   \n",
      "3   4   \\n  輝達飆4％、台積電ADR漲3％ 台指期夜盤劍指23K關卡\\n   \n",
      "4   5           \\n  大樂透頭獎連13摃  下期上看4.4億元\\n   \n",
      "\n",
      "                                          content_en  \n",
      "0  Here's the translation of the news article in ...  \n",
      "1  Here's the translation of the news article:\\n\\...  \n",
      "2  Here's the translation of the news article:\\n\\...  \n",
      "3  Here's the translation of the news article in ...  \n",
      "4  Here's the translation of the news article:\\n\\...  \n"
     ]
    }
   ],
   "source": [
    "# Postgres creds (URL-encode the password)\n",
    "USER = \"postgres\"\n",
    "PASSWORD = quote_plus(\"4b.3O_XD?C9\")\n",
    "HOST = \"18.162.51.182\"\n",
    "PORT = 5432\n",
    "DBNAME = \"mydb\"\n",
    "\n",
    "DB_URL = f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/{DBNAME}\"\n",
    "engine = create_engine(DB_URL)\n",
    "query = f\"\"\"\n",
    "    SELECT id, title, content_en \n",
    "    FROM news \n",
    "    LIMIT {SAMPLE_SIZE}\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, engine)\n",
    "print(f\"Loaded {len(df)} articles\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3eb1cec76a34a799304a9650f575f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Embed content\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCreating embeddings...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m corpus_embeddings \u001b[39m=\u001b[39m embedder\u001b[39m.\u001b[39;49mencode(df[\u001b[39m\"\u001b[39;49m\u001b[39mcontent_en\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues, batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE, show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEmbeddings shape: \u001b[39m\u001b[39m{\u001b[39;00mcorpus_embeddings\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1052\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m features\u001b[39m.\u001b[39mupdate(extra_features)\n\u001b[1;32m   1051\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> 1052\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1053\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhpu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1054\u001b[0m         out_features \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1133\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m             module_kwarg_keys \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_kwargs\u001b[39m.\u001b[39mget(module_name, [])\n\u001b[1;32m   1128\u001b[0m         module_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1129\u001b[0m             key: value\n\u001b[1;32m   1130\u001b[0m             \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1131\u001b[0m             \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m module_kwarg_keys \u001b[39mor\u001b[39;00m (\u001b[39mhasattr\u001b[39m(module, \u001b[39m\"\u001b[39m\u001b[39mforward_kwargs\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39min\u001b[39;00m module\u001b[39m.\u001b[39mforward_kwargs)\n\u001b[1;32m   1132\u001b[0m         }\n\u001b[0;32m-> 1133\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodule_kwargs)\n\u001b[1;32m   1134\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:437\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[1;32m    431\u001b[0m trans_features \u001b[39m=\u001b[39m {\n\u001b[1;32m    432\u001b[0m     key: value\n\u001b[1;32m    433\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m features\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minputs_embeds\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    435\u001b[0m }\n\u001b[0;32m--> 437\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    438\u001b[0m token_embeddings \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    439\u001b[0m features[\u001b[39m\"\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m token_embeddings\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:482\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    481\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 482\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    483\u001b[0m     embedding_output,\n\u001b[1;32m    484\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    485\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    486\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    487\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    488\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    489\u001b[0m )\n\u001b[1;32m    490\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    491\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:334\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    332\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 334\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    335\u001b[0m     hidden_states,\n\u001b[1;32m    336\u001b[0m     attention_mask,\n\u001b[1;32m    337\u001b[0m     head_mask[i],\n\u001b[1;32m    338\u001b[0m     position_bias,\n\u001b[1;32m    339\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    340\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    341\u001b[0m )\n\u001b[1;32m    342\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    344\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:293\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    285\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    286\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    292\u001b[0m ):\n\u001b[0;32m--> 293\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    294\u001b[0m         hidden_states,\n\u001b[1;32m    295\u001b[0m         attention_mask,\n\u001b[1;32m    296\u001b[0m         head_mask,\n\u001b[1;32m    297\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    298\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    300\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    301\u001b[0m     outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:234\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    227\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    235\u001b[0m         hidden_states,\n\u001b[1;32m    236\u001b[0m         attention_mask,\n\u001b[1;32m    237\u001b[0m         head_mask,\n\u001b[1;32m    238\u001b[0m         position_bias,\n\u001b[1;32m    239\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(self_outputs[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m hidden_states)\n\u001b[1;32m    242\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/transformers/models/mpnet/modeling_mpnet.py:162\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    153\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    154\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    160\u001b[0m ):\n\u001b[1;32m    161\u001b[0m     q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq(hidden_states)\n\u001b[0;32m--> 162\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk(hidden_states)\n\u001b[1;32m    163\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv(hidden_states)\n\u001b[1;32m    165\u001b[0m     q \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(q)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/mambaforge3/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize embedding model\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "# Embed content\n",
    "print(\"Creating embeddings...\")\n",
    "corpus_embeddings = embedder.encode(df[\"content_en\"].values, batch_size=BATCH_SIZE, show_progress_bar=True)\n",
    "print(f\"Embeddings shape: {corpus_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing dimensions with UMAP...\n",
      "Reduced embeddings shape: (200, 5)\n"
     ]
    }
   ],
   "source": [
    "# Embed content\n",
    "print(\"Creating embeddings...\")\n",
    "corpus_embeddings = embedder.encode(df[\"content_en\"].values, batch_size=BATCH_SIZE, show_progress_bar=True)\n",
    "print(f\"Embeddings shape: {corpus_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction with UMAP\n",
    "print(\"Reducing dimensions with UMAP...\")\n",
    "reduced_embeddings = umap.UMAP(**UMAP_KWARGS).fit_transform(corpus_embeddings)\n",
    "print(f\"✅ Reduced embeddings shape: {reduced_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Number of clusters found: 3\n"
     ]
    }
   ],
   "source": [
    "# Clustering with HDBSCAN\n",
    "print(\"🧩 Clustering with HDBSCAN...\")\n",
    "clusterer = hdbscan.HDBSCAN(**HDBSCAN_KWARGS)\n",
    "labels = clusterer.fit_predict(reduced_embeddings)\n",
    "df[\"label\"] = [str(label) for label in labels]\n",
    "print(f\"✅ Number of clusters found: {len(set(labels)) - (1 if -1 in labels else 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Embeddings diagnostics:\n",
      "Embeddings range: -6.14 to 8.66\n",
      "Embeddings mean: 2.93 ± 4.31\n",
      "\n",
      "🔍 Finding optimal cluster count...\n",
      "For n_clusters = 2, silhouette score = 0.56\n",
      "For n_clusters = 3, silhouette score = 0.44\n",
      "For n_clusters = 4, silhouette score = 0.52\n",
      "For n_clusters = 5, silhouette score = 0.59\n",
      "For n_clusters = 6, silhouette score = 0.62\n",
      "For n_clusters = 7, silhouette score = 0.61\n",
      "For n_clusters = 8, silhouette score = 0.58\n",
      "For n_clusters = 9, silhouette score = 0.48\n",
      "For n_clusters = 10, silhouette score = 0.50\n",
      "\n",
      "✅ Optimal cluster count: 6 (score: 0.62)\n",
      "\n",
      "🔄 Running final clustering...\n",
      "\n",
      "🔄 Creating visualization...\n",
      "\n",
      "🔄 Naming clusters...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           " \n  谷歌在美砸250億美元 建資料中心和AI基礎設施\n"
          ],
          [
           " \n  川普再度施壓Fed調降利率\n"
          ],
          [
           " \n  輝達飆4％、台積電ADR漲3％ 台指期夜盤劍指23K關卡\n"
          ],
          [
           " \n  川普：與印尼達成關稅協議\n"
          ],
          [
           " \n  記憶體下半年市況遭唱衰 美光股價摔\n"
          ],
          [
           " \n  祖克伯：Meta擬斥資數千億美元推動超級智慧發展\n"
          ],
          [
           " \n  AI搶華爾街飯碗  高盛首創引進AI員工\n"
          ],
          [
           " \n  銀行業財報打頭陣  摩根富國花旗優預期\n"
          ],
          [
           " \n  關稅休戰期急拉貨 洛杉磯港6月吞吐量寫新高\n"
          ],
          [
           " \n  蘋果投資5億美元與美國稀土供應商MP Materials合作\n"
          ],
          [
           " \n  百度無人駕駛汽車將引進Uber全球平台 股價盤前大漲\n"
          ],
          [
           " \n  市場高息需求增溫 安聯00984A連續兩天溢價\n"
          ],
          [
           " \n  投審司：前六月外資來台投資74.6億美元\n"
          ],
          [
           " \n  大陸限制出口技術目錄調整 新增電池正極材料制備技術\n"
          ],
          [
           " \n  美國6月CPI年增2.7％ 今年2月以來新高\n"
          ],
          [
           " \n  壯大資產管理論壇》私募資產親民化成全球趨勢  南怡君：台灣有很大成長空間\n"
          ],
          [
           " \n  國泰金總座李長庚：關稅與匯率需中性看待 對台企長期競爭力有信心\n"
          ],
          [
           " \n  關稅與房市降溫打擊  中小企業5月放款增額創10年同期新低\n"
          ],
          [
           "歐盟延後對美國的報復性貿易關稅"
          ],
          [
           " \n  傳川普將公布700億美元AI與能源投資案\n"
          ],
          [
           "記者走訪全球最大稀土礦場 中國稀土供應鏈背後的污染遺害"
          ],
          [
           "貝森特：Fed主席遴選程序已展開  盼鮑爾也退出理事會 - 國際 - 自由時報電子報"
          ],
          [
           "稀土的代價：中國主產區被污染的水源和傷痕累累的山丘"
          ],
          [
           " \n  30年期美債殖利率漲破5％ 6月初以來首見\n"
          ],
          [
           " \n  晨星電力今年轉供綠電容量 預計將大於300MW\n"
          ],
          [
           " \n  聯準會傳聲筒：6月CPI不會改變Fed政策方向\n"
          ],
          [
           " \n  達新旗下中越廠預計明年春天完成擴產\n"
          ],
          [
           "特朗普向普京發出最後通牒，烏克蘭人卻感到難抱期望"
          ],
          [
           "中國上半年GDP增長5.3%：關稅壓力下顯「韌性」  但下半年需求端或「斷崖式下跌」"
          ],
          [
           "特朗普承諾軍援，象徵烏克蘭戰事的重要突破"
          ],
          [
           "伊朗戰場遇挫後 中國殲-10戰機將成為「救命稻草」？"
          ],
          [
           "特朗普威脅對俄羅斯加徵關稅，並公布對烏克蘭軍援計劃"
          ],
          [
           "特朗普宣佈14國新關稅稅率但最後期限延長三週"
          ],
          [
           "特朗普向金磚國家威脅加徵10%關稅"
          ],
          [
           "特朗普關稅戰：90天暫緩期將盡，亞洲製造業正在如何重塑？"
          ],
          [
           "穩定幣合法化浪潮：新的「金融基礎設施」還是「貨幣主權戰場」？"
          ],
          [
           "稀土、達爾文港或楊恆均案？ 澳洲總理阿爾巴尼斯訪華的五大看點"
          ],
          [
           "印度和中國努力重建關係，但保持謹慎的態度"
          ],
          [
           "中國雙航母「遼寧」號及「山東」號穿越太平洋「第二島鏈」意味著什麼？"
          ],
          [
           "「海鯤艦」海測：台灣第一艘突破技術封鎖的「國造潛艦」五大看點"
          ],
          [
           "人工智慧會威脅水資源嗎？"
          ],
          [
           "美駐聯合國大使提名人瓦爾茲 誓言重塑聯合國、反制中國影響力 - 國際 - 自由時報電子報"
          ],
          [
           "美國放行H20　陸商務部：應繼續取消不合理限制"
          ],
          [
           "黃仁勳見大陸商務部長：中國市場非常有吸引力！"
          ],
          [
           "聯合國安理會緊急會議　敘利亞指控：以色列破壞敘國穩定"
          ],
          [
           "美前官員揭川普關稅終極目標！　南韓就算談成「最低課15%」"
          ],
          [
           "陸商務部列2024數據　王文濤再談中美經貿關係：人為脫鉤是脫不掉的"
          ],
          [
           "中國連續3月減持美債　持倉規模降至16年最低"
          ],
          [
           "中國發現新稀土礦「釹黃河礦」　可作高性能永磁材料核心成分"
          ]
         ],
         "hovertemplate": "cluster_name=states google | federal reserve | power grid<br>x=%{x}<br>y=%{y}<br>title=%{customdata[0]}<extra></extra>",
         "legendgroup": "states google | federal reserve | power grid",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "states google | federal reserve | power grid",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          3.022218704223633,
          4.731387138366699,
          3.852788209915161,
          4.817384719848633,
          4.012784004211426,
          3.030677556991577,
          3.1752190589904785,
          4.230471611022949,
          5.014798641204834,
          3.166706085205078,
          3.41929292678833,
          3.9064342975616455,
          3.678626537322998,
          2.9347198009490967,
          4.57869291305542,
          3.7089035511016846,
          4.653747081756592,
          3.8110344409942627,
          4.817864894866943,
          2.912580966949463,
          2.9641730785369873,
          4.662407398223877,
          2.8512301445007324,
          4.461831569671631,
          3.653670310974121,
          4.6399335861206055,
          3.398428440093994,
          5.021176338195801,
          5.0196533203125,
          5.020458698272705,
          5.456583499908447,
          5.189737319946289,
          4.941190242767334,
          4.961338520050049,
          5.105225563049316,
          3.7958807945251465,
          5.468125820159912,
          5.419797897338867,
          5.451474189758301,
          5.531489372253418,
          3.143206834793091,
          5.3742876052856445,
          5.275306224822998,
          3.3072123527526855,
          5.177490234375,
          4.836570739746094,
          5.165368556976318,
          4.5030083656311035,
          2.847437620162964
         ],
         "xaxis": "x",
         "y": [
          -8.003643035888672,
          -5.365847110748291,
          -7.3748555183410645,
          -4.8593645095825195,
          -7.0673747062683105,
          -7.935460090637207,
          -7.673679351806641,
          -6.845731258392334,
          -5.907311916351318,
          -7.783493518829346,
          -7.570691108703613,
          -7.147843837738037,
          -7.331780910491943,
          -8.231910705566406,
          -5.738585472106934,
          -7.299523830413818,
          -6.490438938140869,
          -7.166568279266357,
          -4.701298713684082,
          -8.198673248291016,
          -8.146425247192383,
          -5.303583145141602,
          -8.257549285888672,
          -6.572261810302734,
          -7.36890172958374,
          -5.44666051864624,
          -7.602581977844238,
          -4.920238494873047,
          -6.088156700134277,
          -4.896942138671875,
          -5.806651592254639,
          -4.783991813659668,
          -5.089880466461182,
          -4.824673652648926,
          -6.298811435699463,
          -7.315420627593994,
          -6.059595108032227,
          -5.948210716247559,
          -5.9803643226623535,
          -6.085025787353516,
          -7.833637237548828,
          -5.381230354309082,
          -6.271646022796631,
          -7.558813095092773,
          -5.089427471160889,
          -4.848078727722168,
          -6.12270975112915,
          -6.541614055633545,
          -8.263718605041504
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           " \n  台電員工遭高壓線路電擊　卓榮泰關注不捨\n"
          ],
          [
           " \n  台灣大出動百人馳援通訊 9成障礙基站已修復\n"
          ],
          [
           " \n  台南剩597戶未復電 台電搶修進尾聲：最快今晚全面來電\n"
          ],
          [
           "台鐵潮州站號誌故障深夜終於修復！ 影響64列次 - 生活 - 自由時報電子報"
          ],
          [
           "大溪普濟堂關公誕辰遶境7/17遇防空演習 警方交管一次看 - 生活 - 自由時報電子報"
          ],
          [
           "台泥子公司三元能源大火 高雄市府初判肇災原因出爐 - 生活 - 自由時報電子報"
          ],
          [
           "台灣「漢光演習」五大看點：動員創新高、超市首度納入「持久戰」部署"
          ],
          [
           "漢光41》金門花崗石醫院變野戰醫院 金防部演練戰傷救護與後送 - 自由軍武頻道"
          ],
          [
           "獨家》麥當勞爆炸案33年後退休 葛永興憶殉職同袍：心中始終留空位給他 - 社會 - 自由時報電子報"
          ],
          [
           "台電人員嘉義維修遭電擊 送醫搶救裝葉克膜維生 | 社會 | Newtalk新聞"
          ],
          [
           "公車擦撞變電箱　板橋後站商圈部分店家停電 | 社會 | Newtalk新聞"
          ],
          [
           "快訊》21:58臺灣南部海域發生規模4.8有感地震 最大震度屏東縣鵝鑾鼻3級 | 生活 | Newtalk新聞"
          ],
          [
           "台電工作人員嘉縣義竹維修遭電擊　命危送醫 | 社會 | Newtalk新聞"
          ],
          [
           "卓揆赴台中視察城鎮韌性演習 期許持續深化全民防衛意識 | 社會 | Newtalk新聞"
          ],
          [
           "慰勉1350位投入災後復原替代役男 內政部長劉世芳：表達感謝 | 社會 | Newtalk新聞"
          ],
          [
           "中部城鎮韌性演習　台中男硬騎車最高可罰15萬 | 社會 | Newtalk新聞"
          ],
          [
           "一天狂降暴雨426mm！韓光州星巴克「泥水灌進店內」　招牌慘滅頂"
          ],
          [
           " \n  遠傳動員上千人次支援災區 整體修復率已近95％\n"
          ],
          [
           "阿富汗資料外洩引發前所未有秘密撤離：值得關注的三大關鍵問題"
          ],
          [
           "你最喜歡的健康飲料會損害牙齒嗎？"
          ],
          [
           "監管機構稱波音飛機燃油開關鎖設計安全"
          ],
          [
           "台灣提升軍人待遇：加薪、搭機優惠為何引發爭議？"
          ],
          [
           "朝鮮的「西班牙班尼多姆式」度假村迎來首批俄羅斯遊客"
          ],
          [
           "從「臉基尼」到「水上麻將」：中國高溫下民眾尋涼方"
          ],
          [
           "日本7/5發生大地震？「末日預言」為何引發遊客恐慌"
          ],
          [
           "甘肅幼兒園鉛中毒學童超過200，用有毒顏料製作食品"
          ],
          [
           "哈士奇「吃室友」生吞2陸龜！一臉無辜被抬進醫院　飼主嚇瘋"
          ],
          [
           "台灣人年吞10億顆安眠藥　40歲女吃到腦霧「半夜無意識煮飯」"
          ],
          [
           "常見病毒可增加阿茲海默症風險，但也是治療關鍵？"
          ],
          [
           "機上久坐恐釀血栓！醫：「這些人」搭機需特別注意"
          ],
          [
           "全球唯一！「喝咖啡賞北韓」星巴克爆紅　開幕7個月湧12萬人"
          ],
          [
           "沒衛生！手機掉進整鍋芋頭 飲料店女員工「用湯匙撈出」PO限動被罵翻"
          ],
          [
           "湖北唯一錄取空軍預警學院女孩現身　畢業後願去雷達站吃苦"
          ],
          [
           "湖北地表溫度73℃！女子坐石頭10秒致三度燙傷　醫嘆：要清創植皮"
          ],
          [
           "陸男太陽下吃米線褲子燒穿一個洞　拿紙巾測試真燒起來"
          ],
          [
           "英短三花「初見飲水機」手好奇狂撥　發現一直有水震驚到立正"
          ],
          [
           "你敢吃鼻屎嗎？專家曝「助免疫又能護牙」　研究：靠這5招更安心│TVBS新聞網"
          ],
          [
           "英政府誤外洩阿富汗人個資　牽連MI6特務、SAS特種部隊"
          ],
          [
           "趕著去接兒子！　印度爸「劇毒眼鏡蛇掛脖子」被咬死"
          ],
          [
           "陸「老年暴走團」擋消防車出勤　堅持維持隊形「寸土不讓」惹議"
          ],
          [
           "蚊子都熱死了！河南地表溫度直逼73℃　居民：可煎蛋烤蝦了"
          ],
          [
           "伊拉克商場大火61死！剛開幕「整棟燒毀」14焦屍難辨　疑冷氣爆炸"
          ],
          [
           "陸男「生水刷牙」說不出話！大腦遭10公分「裂頭絛蟲」入侵"
          ],
          [
           "俄士兵「瓶裝水遭下毒」4人全身抽搐死亡！　生前痛苦倒地畫面曝"
          ],
          [
           "導航亂帶路母子受困沒訊號森林　靠2張「手寫求救字條」獲救"
          ],
          [
           "北海道棕熊頻繁出沒！獵人深夜出動「開槍擊斃」　將驗胃部與DNA"
          ],
          [
           "薇帕颱風「最接近台灣」時間點曝！　日氣象廳最新預測路徑"
          ],
          [
           "校外教學悲劇！英70人校車「失控墜6公尺邊坡」　釀22人死傷"
          ]
         ],
         "hovertemplate": "cluster_name=taiwan power | injured zhuō | article typhoon<br>x=%{x}<br>y=%{y}<br>title=%{customdata[0]}<extra></extra>",
         "legendgroup": "taiwan power | injured zhuō | article typhoon",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "taiwan power | injured zhuō | article typhoon",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          15.25545883178711,
          15.385287284851074,
          15.428665161132812,
          15.32001781463623,
          14.130746841430664,
          16.036819458007812,
          14.019140243530273,
          14.660877227783203,
          14.048989295959473,
          15.355364799499512,
          15.589532852172852,
          14.63744831085205,
          15.685359001159668,
          14.33173942565918,
          14.184652328491211,
          14.41634464263916,
          16.18973159790039,
          15.365304946899414,
          14.486923217773438,
          17.023527145385742,
          15.794500350952148,
          14.062112808227539,
          14.705891609191895,
          16.206205368041992,
          15.62043571472168,
          16.917695999145508,
          17.060428619384766,
          17.038127899169922,
          17.153112411499023,
          15.77086353302002,
          14.695422172546387,
          16.72054672241211,
          13.960346221923828,
          16.19706153869629,
          16.37126350402832,
          16.47382164001465,
          17.21912384033203,
          14.447260856628418,
          17.11185646057129,
          14.098023414611816,
          16.251638412475586,
          15.918415069580078,
          17.26862907409668,
          16.913625717163086,
          14.805976867675781,
          14.75467586517334,
          15.407669067382812,
          15.279256820678711
         ],
         "xaxis": "x",
         "y": [
          0.8522301912307739,
          0.9625688791275024,
          1.07002592086792,
          1.0915436744689941,
          0.19312141835689545,
          0.5475941300392151,
          0.3359118103981018,
          0.3856237530708313,
          0.17850664258003235,
          0.6400262713432312,
          0.9036397933959961,
          0.7460039258003235,
          0.837846040725708,
          0.5891782641410828,
          0.474336177110672,
          0.6767465472221375,
          -0.12091335654258728,
          1.0777283906936646,
          0.07626639306545258,
          -0.5754084587097168,
          0.781997561454773,
          0.3849043548107147,
          -0.14549055695533752,
          0.19451548159122467,
          12.706851959228516,
          -0.4627496302127838,
          -0.6420853137969971,
          -0.6005651950836182,
          -0.7089858651161194,
          0.6344560384750366,
          -0.13653191924095154,
          -0.3277510404586792,
          0.1788489669561386,
          0.25224608182907104,
          0.16290289163589478,
          -0.21255895495414734,
          -0.6357241272926331,
          0.16312210261821747,
          -0.7011430263519287,
          0.08860328048467636,
          0.15747134387493134,
          0.3856954574584961,
          -0.8390385508537292,
          -0.4699634313583374,
          0.6059005260467529,
          0.5679088830947876,
          1.1042522192001343,
          0.5587435364723206
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           " \n  大樂透頭獎連13摃  下期上看4.4億元\n"
          ],
          [
           "陳晨威拚全壘打大賽自認「漢草」差　但林子偉看好 | 體育 | Newtalk新聞"
          ],
          [
           " \n  兩岸青年以球會友 強化體育學術交流\n"
          ],
          [
           " \n  雙橡園開發單站冠名贊助TPGA「頂粵吉品公開賽」  七國選手齊聚爭奪世界積分\n"
          ],
          [
           "亞洲盃女籃》台灣對哈薩克開賽打得拉鋸 邱啟益：有提醒大家她們就是來打架 - 自由體育"
          ],
          [
           "中職》郭天信猛打賞貢獻5分打點！坦言6月狀況不理想 - 自由體育"
          ],
          [
           "中職》味全龍12：4勝台鋼雄鷹 近5戰拿4勝得43分 - 自由體育"
          ],
          [
           "瓊斯盃》被賀丹「顏扣」也沒躲開 徐堂琪：失誤要盡全力守回來 - 自由體育"
          ],
          [
           "瓊斯盃》地貼太滑恐危害球員 職籃工會提3點訴求 - 自由體育"
          ],
          [
           "亞洲盃女籃二級賽　台灣預賽全勝晉4強 | 體育 | Newtalk新聞"
          ],
          [
           "楊博涵與劉廣珩打敗世界第9  日本羽球賽晉16強 | 體育 | Newtalk新聞"
          ],
          [
           "世上最年長馬拉松跑者車禍過世　享壽114歲 | 體育 | Newtalk新聞"
          ],
          [
           "黃子鵬下二軍修正控球  林立歸隊時間點讓本人評估 | 體育 | Newtalk新聞"
          ],
          [
           "德國世大運將開幕　陳弈通、楊亞依擔任掌旗官 | 體育 | Newtalk新聞"
          ],
          [
           "看林智勝陽耀勳拚全壘打大賽有憧憬  宋晟睿參賽圓夢 | 體育 | Newtalk新聞"
          ],
          [
           "李博登失分多平野惠一提出觀察　兄弟續物色新洋投 | 體育 | Newtalk新聞"
          ],
          [
           "林子偉曾在大聯盟蹲捕　明星賽與葉君璋、高志綱競技 | 體育 | Newtalk新聞"
          ],
          [
           "當你跑了366場馬拉松之後，你的心臟會發生什麼事？"
          ],
          [
           "史上第一「人體超越音速」！　56歲太空跳傘傳奇命喪滑翔傘事故"
          ],
          [
           "一張彩券改變人生　街友刮中「2千多萬大獎」驚喜：想買房養狗"
          ],
          [
           "杜蘭特、烏多卡期待聯手！　盼「訓練態度」帶動火箭小將"
          ],
          [
           "老鷹今夏補強2大奪冠拼圖　一哥楊恩是關鍵推手！"
          ],
          [
           "全NBA只剩勇士「零補強」　專家：交易庫明加仍無法化解危機"
          ],
          [
           "道奇強打貝茲遭遇低潮　總教練羅伯斯不忍了！直接調離先發名單 - 民視新聞網"
          ],
          [
           "勇士大物尋求年薪7.3億合約　庫明加希望被交易到公牛"
          ]
         ],
         "hovertemplate": "cluster_name=outfielder chen | win chen | derby chen<br>x=%{x}<br>y=%{y}<br>title=%{customdata[0]}<extra></extra>",
         "legendgroup": "outfielder chen | win chen | derby chen",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "outfielder chen | win chen | derby chen",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          5.636260032653809,
          4.314975738525391,
          5.414097785949707,
          5.709945201873779,
          5.217796802520752,
          4.261773109436035,
          4.248329162597656,
          5.102686882019043,
          5.168694972991943,
          5.330163955688477,
          5.237227439880371,
          4.565157890319824,
          4.209293842315674,
          5.269843101501465,
          4.196412563323975,
          4.145627975463867,
          4.129387855529785,
          4.6415629386901855,
          4.7247633934021,
          5.551843643188477,
          4.458465576171875,
          4.387007713317871,
          4.368431091308594,
          4.287307262420654,
          4.433746337890625
         ],
         "xaxis": "x",
         "y": [
          10.778207778930664,
          8.152381896972656,
          10.373051643371582,
          10.863272666931152,
          10.114086151123047,
          8.130356788635254,
          8.25770378112793,
          9.979762077331543,
          10.070988655090332,
          10.271319389343262,
          10.151509284973145,
          9.038118362426758,
          8.100235939025879,
          10.189337730407715,
          8.336737632751465,
          8.180880546569824,
          8.412461280822754,
          9.116726875305176,
          9.200495719909668,
          10.670477867126465,
          8.811592102050781,
          8.733131408691406,
          8.719356536865234,
          8.0280179977417,
          8.758794784545898
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           " \n  別等離職才後悔！上班族一定要先做的事\n"
          ],
          [
           "白委罷不了 徐巧芯：目標變成我們合理嗎？"
          ],
          [
           "看不下去了！葉元之霸凌已故助理對話曝光 胡采蘋：該被降職降薪的是他 - 政治 - 自由時報電子報"
          ],
          [
           "盜綠委圖卡粗糙P圖被抓包 民眾黨蔡春綢道歉：形式上不謹慎 - 政治 - 自由時報電子報"
          ],
          [
           "邊看筆電邊回答 京華城案證人胡方瓊卻翻供...檢曝原因 - 社會 - 自由時報電子報"
          ],
          [
           "禿子漢子燕子再聚 國民黨「反惡罷、顧桃園」守護民主之夜20日中壢登場 - 政治 - 自由時報電子報"
          ],
          [
           "(影)《矢板明夫Newtalk》大罷免投票率飆高 背後無人動員？ 國民黨還以為只是「藍綠對決」？ | 政治 | Newtalk新聞"
          ],
          [
           "「斷健不退縮」！綠營開催票戰　吳思瑤、林楚茵台中催票衝高聲量 | 政治 | Newtalk新聞"
          ],
          [
           "洪孟楷控罷團造謠買票走路工　赴新北檢提告 | 社會 | Newtalk新聞"
          ],
          [
           "（影）5綠委集結中六站路口 疾呼罷掉羅廷瑋這個「國會小混混」 | 政治 | Newtalk新聞"
          ],
          [
           "台灣「大罷免」事件始末、政黨表態及投票流程等一次看"
          ],
          [
           "中國「709大抓捕」維權律師向BBC述說出獄後的監控人生"
          ],
          [
           "誇張！救災爆口角就亮刀 里幹事稱「自保」惹眾怒"
          ],
          [
           "7年未加薪5年沒領到獎金　大馬女子「不跳槽」理由曝光"
          ],
          [
           "許崑源遺孀率婦團力挺 張善政再赴花蓮支持傅崐萁鄉親沿街讚聲"
          ],
          [
           "巨乳妹賣淫脫光後「胸部大縮水」！3老司機控詐騙　極樂4P夢碎報警"
          ],
          [
           "陸老人離世留2千萬遺產無人繼承　全網尋顧姓親人接贈"
          ],
          [
           "民眾黨集會民進黨中央嗆聲 林國成國罵賴清德「X你娘」"
          ],
          [
           "2年被爆打16次！人妻身上「留30公分傷疤」終身掛便袋"
          ],
          [
           "撞見妻與陌生人進摩鐵！越男心酸帶3孩驗DNA　揭穿她多年祕密"
          ],
          [
           "國民黨反罷喊\"再愛我一次\" 林右昌：恐怖愛人不值得再愛一次 - 民視新聞網"
          ]
         ],
         "hovertemplate": "cluster_name=resignation | resignation tomorrow | continue working<br>x=%{x}<br>y=%{y}<br>title=%{customdata[0]}<extra></extra>",
         "legendgroup": "resignation | resignation tomorrow | continue working",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "resignation | resignation tomorrow | continue working",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          16.495216369628906,
          15.925970077514648,
          16.592601776123047,
          16.032960891723633,
          16.257543563842773,
          15.699676513671875,
          15.537965774536133,
          16.233905792236328,
          15.819846153259277,
          15.932280540466309,
          15.853010177612305,
          8.674640655517578,
          15.58356761932373,
          16.48350715637207,
          16.160755157470703,
          8.206801414489746,
          8.589888572692871,
          16.087865829467773,
          8.450352668762207,
          8.435075759887695,
          15.910135269165039
         ],
         "xaxis": "x",
         "y": [
          13.309296607971191,
          13.253641128540039,
          13.27826976776123,
          13.164697647094727,
          13.084868431091309,
          13.00387954711914,
          12.787698745727539,
          13.260915756225586,
          13.001240730285645,
          13.081212043762207,
          13.03279972076416,
          12.360209465026855,
          13.020209312438965,
          13.295727729797363,
          13.036054611206055,
          12.268238067626953,
          12.708207130432129,
          13.212723731994629,
          12.414217948913574,
          12.44490909576416,
          12.789722442626953
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "菜市場時段性禁車？ 攤販:安全.買氣難兼顧"
          ],
          [
           "愛潑斯坦案：該案為何在「讓美國再次偉大」陣營中備受關注"
          ],
          [
           " \n  演唱會經濟熱潮！GD、五月天、江蕙接力開唱 百貨商場搶攻粉絲荷包\n"
          ],
          [
           " \n  韓流魅力席捲百貨！車銀優、DKB、猛男秀帶動韓星周邊搶購潮\n"
          ],
          [
           " \n  街口支付最新公告！8成品牌通路恢復使用 30大商家一次看\n"
          ],
          [
           "被納粹偷走流浪80年 龐貝古城拼貼春宮畫物歸原地 - 國際 - 自由時報電子報"
          ],
          [
           " \n  父親節促銷戰  按摩椅與健身器材業提前開打\n"
          ],
          [
           "中國高校擬因在校女生與外籍男子「不正當交往」開除其學籍，稱其「有損國格」"
          ],
          [
           "「魷魚遊戲」下結業潮來襲，香港餐飲業能重返「美食天堂」嗎？"
          ],
          [
           "特朗普接受BBC訪問：「我對普京感到失望，但尚未放棄與他的關係」"
          ],
          [
           "正式預告「完全零台詞」超震撼！林依晨四度合作張孝全…首演夫妻"
          ],
          [
           "體壇造星：中國運動員如何頂著「飯圈」爭議成為新一代頂流明星"
          ],
          [
           "柴靜： 從中國官媒的知名記者和「公知」到出走海外的獨立媒體人"
          ],
          [
           "Labubu走紅背後的營銷爆點、盲盒模式與穀子經濟"
          ],
          [
           "演化專家：為什麼人類天生喜歡八卦？"
          ],
          [
           "在工作中哭泣：是堅強的表現、軟弱的象徵，還是人之常情？"
          ],
          [
           "朴軫永曬父女同框照！　女兒真面目「根本複製貼上」網驚：也長太像"
          ],
          [
           "汪峰賣線上課「銷量超悽慘」　情史精彩挨嘲：不如教怎追女神"
          ],
          [
           "《雞與牛》導演推新作！聯手《小小兵》動畫師「豬排變特務抓象」"
          ],
          [
           "《007》龐德女郎痛訴遭家暴！　超慘傷照曝光"
          ],
          [
           "台灣珍奶太好喝！徐玄來台暴走「1天內狂灌6杯」：深刻記得這件事"
          ],
          [
           "不甩不倫風波！田中圭赴美打撲克大賽　「贏走300萬」驚人實力曝光"
          ],
          [
           "曾沛慈call out《星光》超大咖戰友幫唱　她竟差點忘詞！"
          ],
          [
           "「清純歌手」突瘋狂蹭牆！驚爆性愛成癮染病　代表作很多人翻唱"
          ],
          [
           "一週親3次！謝京穎放閃張書偉「吻戲免報備」　大讚老公這點超棒"
          ],
          [
           "松屋連皇室也愛吃！日媒曝悠仁親王「庶民生活」　打球吃飯超親民"
          ],
          [
           "川普爆手繪「裸女圖」送淫魔富商　署名簽在私處！本人氣炸否認"
          ],
          [
           "賴慧如演媽媽太像「真實年紀被遺忘」！洩心聲：這是演員要做到的"
          ],
          [
           "44歲孫淑媚被網讚「台版Jennie」！　釣出本尊回應了"
          ],
          [
           "遭叔伯逼面對父債…林柏宏首露面回應！每天5點起床：還在學習路上"
          ],
          [
           "差49歲！20歲新娘「見新郎真面目」嚇暈影片瘋傳　真相曝光"
          ],
          [
           "64歲周華健「情書」曝光了！　「蕾絲花邊」自虧：是怪作品"
          ],
          [
           "《鬼滅之刃無限城篇》日本上映首日！電影院擠滿人…周邊一早賣光"
          ],
          [
           "賈永婕被控「拿公關票帶關穎買GD周邊」！嚴肅首反擊：照片在哪裡"
          ],
          [
           "食農市集「書與農」的小宇宙等民眾尋寶"
          ],
          [
           "周湯豪出道15週年宣布好消息！　甜蜜告白：你對我來說有多重要　"
          ],
          [
           "快訊／賈永婕道歉！　回應GD展覽之亂：沒把任何留言當耳邊風"
          ],
          [
           "《逆愛》宣布今晚復播！　「5天內播4集」粉絲嗨翻：終於等到了"
          ],
          [
           "快訊／南韓最大頒獎典禮「金唱片」移駕台灣辦　1月10日登上大巨蛋"
          ],
          [
           "好萊塢大咖合體2港星！柯林法洛澳門「變賭徒」夢幻聯動金馬影后"
          ],
          [
           "孫德榮坦承冷凍過陳喬恩  遺產受惠人數曝光 「不留一分給孫家！」"
          ],
          [
           "廣末涼子「車禍罹病停工93天」首發聲！認還需要時間…大片在等她"
          ],
          [
           "Coldplay演唱會變偷情現場！女方入職半年多　CEO大讚完美人選"
          ],
          [
           "小巨蛋KPOP萬人拼盤9月登場！4組大咖合體　ITZY、NMIXX都有"
          ],
          [
           "專輯提前上線…王嘉爾「我現在才知」　深夜崩潰：沒什麼可再說的了"
          ],
          [
           "Coldplay演唱會抓姦CEO偷吃　「假道歉信」藏細節！前同事酸活該"
          ],
          [
           "快訊／GD展覽辦一天被罵翻！主辦道歉「周邊改預購」：運費我們出"
          ],
          [
           "41歲旅遊網紅西藏自駕途中去世　粉絲嘆：倒在自己最愛的地方"
          ],
          [
           "Coldplay抓包他不倫小三！　網瘋傳「CEO聲明截圖」假道歉信藏惡搞"
          ]
         ],
         "hovertemplate": "cluster_name=market restricts | baoshan market | restricted time<br>x=%{x}<br>y=%{y}<br>title=%{customdata[0]}<extra></extra>",
         "legendgroup": "market restricts | baoshan market | restricted time",
         "marker": {
          "color": "#FFA15A",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "market restricts | baoshan market | restricted time",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          16.08021354675293,
          8.510976791381836,
          8.30112075805664,
          7.9938063621521,
          16.235830307006836,
          5.0068559646606445,
          8.109045028686523,
          6.404395580291748,
          15.765137672424316,
          8.443424224853516,
          4.114994049072266,
          5.92426872253418,
          8.01620101928711,
          8.581098556518555,
          4.924408912658691,
          6.223453044891357,
          5.058994293212891,
          4.576286315917969,
          4.070126056671143,
          6.327794075012207,
          4.850270748138428,
          5.904054164886475,
          4.411962032318115,
          4.783531188964844,
          4.321503162384033,
          4.988223552703857,
          6.1355299949646,
          4.304076671600342,
          4.727950572967529,
          8.217713356018066,
          4.692826271057129,
          4.382777214050293,
          8.467622756958008,
          8.423609733581543,
          8.78630542755127,
          4.52363920211792,
          8.247742652893066,
          4.253746032714844,
          7.768250942230225,
          4.027853012084961,
          7.658838748931885,
          5.2849040031433105,
          6.202797889709473,
          5.103402137756348,
          7.656369209289551,
          6.282943248748779,
          8.327265739440918,
          8.210732460021973,
          6.260762691497803
         ],
         "xaxis": "x",
         "y": [
          12.75055980682373,
          13.146313667297363,
          12.753591537475586,
          13.05704402923584,
          12.986635208129883,
          13.399605751037598,
          13.128950119018555,
          11.700657844543457,
          12.9433012008667,
          13.185626983642578,
          14.047863006591797,
          11.092327117919922,
          13.374473571777344,
          12.683210372924805,
          13.682415008544922,
          11.774360656738281,
          14.22960376739502,
          13.66996955871582,
          14.15649700164795,
          11.72226333618164,
          14.207496643066406,
          11.16617202758789,
          13.825257301330566,
          13.725922584533691,
          13.900036811828613,
          14.238237380981445,
          11.929076194763184,
          13.953869819641113,
          14.253764152526855,
          13.37667179107666,
          13.705294609069824,
          14.007625579833984,
          12.93985652923584,
          12.841856956481934,
          12.510027885437012,
          14.115739822387695,
          12.979880332946777,
          14.017712593078613,
          13.174368858337402,
          14.15483283996582,
          13.415886878967285,
          13.970053672790527,
          11.815722465515137,
          14.093559265136719,
          13.260068893432617,
          11.89286994934082,
          13.19921588897705,
          13.322147369384766,
          11.872937202453613
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "www.ctee.com.tw"
          ],
          [
           "衛生紙丟馬桶會堵塞？環境部闢謠：請相信科學 「安心丟吧」 - 地產天下 - 自由電子報"
          ],
          [
           null
          ],
          [
           null
          ],
          [
           null
          ],
          [
           null
          ],
          [
           "巴西女童「長出81顆牙」！恐怖X光照曝光　患超罕見多生牙"
          ],
          [
           "廣東佛山屈公病例激增 累計達1873例"
          ]
         ],
         "hovertemplate": "cluster_name=supernumerary teeth | teeth multiple | abnormal teeth<br>x=%{x}<br>y=%{y}<br>title=%{customdata[0]}<extra></extra>",
         "legendgroup": "supernumerary teeth | teeth multiple | abnormal teeth",
         "marker": {
          "color": "#19d3f3",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "supernumerary teeth | teeth multiple | abnormal teeth",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -0.29489776492118835,
          -0.3787793815135956,
          -0.28537166118621826,
          -0.1791524738073349,
          -0.4338527023792267,
          -0.4183502793312073,
          -0.2808215618133545,
          -0.29064223170280457
         ],
         "xaxis": "x",
         "y": [
          1.2042210102081299,
          1.2881276607513428,
          1.1946009397506714,
          1.0884435176849365,
          1.3430731296539307,
          1.3276865482330322,
          1.1893517971038818,
          1.1997281312942505
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 700,
        "legend": {
         "title": {
          "text": "cluster_name"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "News Clusters (n=200, k=6)"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Cluster distribution:\n",
      "cluster_name\n",
      "states google | federal reserve | power grid             49\n",
      "market restricts | baoshan market | restricted time      49\n",
      "taiwan power | injured zhuō | article typhoon            48\n",
      "outfielder chen | win chen | derby chen                  25\n",
      "resignation | resignation tomorrow | continue working    21\n",
      "supernumerary teeth | teeth multiple | abnormal teeth     8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add 2D coordinates to dataframe\n",
    "df[\"x\"] = reduced_embeddings[:, 0]\n",
    "df[\"y\"] = reduced_embeddings[:, 1]\n",
    "df[\"text_short\"] = df[\"content_en\"].str[:100] + \"...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 0\n"
     ]
    }
   ],
   "source": [
    "# Optional: Extract keywords per cluster\n",
    "extract_keywords = False\n",
    "if extract_keywords:\n",
    "    kw_model = KeyBERT(model=embedder)\n",
    "    cluster_keywords = {}\n",
    "    for label in df[\"label\"].unique():\n",
    "        if label == \"-1\": continue  # Skip noise\n",
    "        texts = df[df[\"label\"] == label][\"content_en\"].tolist()\n",
    "        joined_text = \" \".join(texts)\n",
    "        keywords = kw_model.extract_keywords(joined_text, top_n=5)\n",
    "        cluster_keywords[label] = [kw[0] for kw in keywords]\n",
    "    print(\"🗝️ Cluster keywords:\", cluster_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "print(\"📊 Plotting results...\")\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"x\", y=\"y\",\n",
    "    color=\"label\",\n",
    "    hover_data=[\"title\", \"text_short\"],\n",
    "    title=\"News Article Clustering\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cluster names...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: electricity google - energy china - reuters trump\n",
      "Cluster 1: taiwan power - power taiwan - taiwan ministry\n",
      "Cluster 2: taiwan lottery - taoyuan team - chén\n",
      "Cluster 3: quitting company - leaving job - left workplace\n",
      "Error processing cluster 4: sequence item 0: expected str instance, NoneType found\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f9d4f5500e5fa8cb2762b8bf86dd8a63cbe4882e3c147fc2b711e49abe0f670"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
